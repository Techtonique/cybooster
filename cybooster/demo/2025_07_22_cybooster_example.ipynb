{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWQhO7q_V7rn"
      },
      "source": [
        "# Boosting with Cybooster\n",
        "\n",
        "This notebook demonstrates the usage of the `cybooster` library for boosting various scikit-learn-like (having `fit` and `predict` methods is enough) estimators on different datasets. It includes examples of regression and classification and time series forecasting tasks. It's worth mentioning that only regressors are accepted in `cybooster`, no matter the task.\n",
        "\n",
        "`cybooster` is a high-performance generic gradient boosting (any based learner can be used) library designed for classification and regression tasks. It is built on Cython (that is, C) for speed and efficiency. This version will also be more GPU friendly, thanks to JAX, making it suitable for large datasets.\n",
        "\n",
        "In `cybooster`, each base learner is augmented with a randomized neural network (a generalization of [https://www.researchgate.net/publication/346059361_LSBoost_gradient_boosted_penalized_nonlinear_least_squares](https://www.researchgate.net/publication/346059361_LSBoost_gradient_boosted_penalized_nonlinear_least_squares) to any base learner), which allows the model to learn complex patterns in the data. The library supports both classification and regression tasks, making it versatile for various machine learning applications.\n",
        "\n",
        "`cybooster` is born from `mlsauce`, that might be difficult to install on some systems (for now). `cybooster` installation is straightforward.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mPTS7eCfhVPM"
      },
      "outputs": [],
      "source": [
        "!pip install cybooster --upgrade --no-cache-dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HyZm7ZaTXfkb"
      },
      "source": [
        "# 1 - Simple example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_7rQQh6mgvxO",
        "outputId": "d3e7162a-6b39-4873-c115-4036f7bc7988"
      },
      "outputs": [],
      "source": [
        "from cybooster import BoosterClassifier, BoosterRegressor\n",
        "from sklearn.datasets import load_iris, load_diabetes, load_breast_cancer, load_digits, load_wine\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error, root_mean_squared_error\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from time import time\n",
        "\n",
        "\n",
        "# Regression Examples\n",
        "X, y = load_diabetes(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "regressor = BoosterRegressor(obj=LinearRegression(), n_estimators=100, learning_rate=0.1,\n",
        "                             n_hidden_features=10, verbose=1, seed=42)\n",
        "start = time()\n",
        "regressor.fit(X_train, y_train)\n",
        "y_pred = regressor.predict(X_test)\n",
        "print(f\"Elapsed: {time() - start} s\")\n",
        "rmse = root_mean_squared_error(y_test, y_pred)\n",
        "print(f\"RMSE for regression: {rmse:.4f}\")\n",
        "\n",
        "# Classification Example\n",
        "X, y = load_iris(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "classifier = BoosterClassifier(obj=LinearRegression(), n_estimators=100, learning_rate=0.1,\n",
        "                               n_hidden_features=10, verbose=1, seed=42)\n",
        "start = time()\n",
        "try:\n",
        "    classifier.fit(X_train, y_train)\n",
        "except Exception as e: # this is for Windows users\n",
        "    y_train = y_train.astype('int32')\n",
        "    classifier.fit(X_train, y_train)\n",
        "y_pred = classifier.predict(X_test)\n",
        "print(f\"Elapsed: {time() - start} s\")\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy for classification: {accuracy:.4f}\")\n",
        "\n",
        "X, y = load_wine(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "classifier = BoosterClassifier(obj=LinearRegression(), n_estimators=100, learning_rate=0.1,\n",
        "                               n_hidden_features=10, verbose=1, seed=42)\n",
        "start = time()\n",
        "try:\n",
        "    classifier.fit(X_train, y_train)\n",
        "except Exception as e: # this is for Windows users\n",
        "    y_train = y_train.astype('int32')\n",
        "    classifier.fit(X_train, y_train)\n",
        "y_pred = classifier.predict(X_test)\n",
        "print(f\"Elapsed: {time() - start} s\")\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy for classification: {accuracy:.4f}\")\n",
        "\n",
        "X, y = load_breast_cancer(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "classifier = BoosterClassifier(obj=LinearRegression(), n_estimators=100, learning_rate=0.1,\n",
        "                               n_hidden_features=10, verbose=1, seed=42)\n",
        "start = time()\n",
        "try:\n",
        "    classifier.fit(X_train, y_train)\n",
        "except Exception as e:\n",
        "    y_train = y_train.astype('int32')\n",
        "    classifier.fit(X_train, y_train)\n",
        "y_pred = classifier.predict(X_test)\n",
        "print(f\"Elapsed: {time() - start} s\")\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy for classification: {accuracy:.4f}\")\n",
        "\n",
        "X, y = load_digits(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "classifier = BoosterClassifier(obj=LinearRegression(), n_estimators=100, learning_rate=0.1,\n",
        "                               n_hidden_features=10, verbose=1, seed=42)\n",
        "start = time()\n",
        "try:\n",
        "    classifier.fit(X_train, y_train)\n",
        "except Exception as e:\n",
        "    y_train = y_train.astype('int32')\n",
        "    classifier.fit(X_train, y_train)\n",
        "y_pred = classifier.predict(X_test)\n",
        "print(f\"Elapsed: {time() - start} s\")\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy for classification: {accuracy:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLPspKHNAuHd"
      },
      "source": [
        "# 2 - Loop on models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-e26q7hAaMh",
        "outputId": "6de29291-66d1-45a0-ab03-dd5735b3a2ae"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.utils import all_estimators\n",
        "from tqdm import tqdm\n",
        "from sklearn.utils.multiclass import type_of_target\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "\n",
        "\n",
        "# Get all scikit-learn regressors\n",
        "estimators = all_estimators(type_filter='regressor')\n",
        "\n",
        "results_regressors = []\n",
        "results_classifiers = []\n",
        "\n",
        "verbose = 0\n",
        "\n",
        "for name, RegressorClass in tqdm(estimators):\n",
        "\n",
        "    if name in ['MultiOutputRegressor', 'MultiOutputClassifier', 'StackingRegressor', 'StackingClassifier',\n",
        "                    'VotingRegressor', 'VotingClassifier', 'TransformedTargetRegressor', 'RegressorChain',\n",
        "                    'GradientBoostingRegressor', 'HistGradientBoostingRegressor', 'RandomForestRegressor',\n",
        "                    'ExtraTreesRegressor', 'MLPRegressor']:\n",
        "\n",
        "        continue\n",
        "\n",
        "    try:\n",
        "      print(f\"\\nRunning with {name}\")\n",
        "      # Regression Examples\n",
        "      X, y = load_diabetes(return_X_y=True)\n",
        "      X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "      regressor = BoosterRegressor(obj=RegressorClass(), n_estimators=100, learning_rate=0.1,\n",
        "                                  n_hidden_features=10, verbose=verbose, seed=42)\n",
        "      start = time()\n",
        "      regressor.fit(X_train, y_train)\n",
        "      y_pred = regressor.predict(X_test)\n",
        "      print(f\"Elapsed: {time() - start} s\")\n",
        "      rmse = root_mean_squared_error(y_test, y_pred)\n",
        "      print(f\"RMSE for regression: {rmse:.4f}\")\n",
        "      results_regressors.append([\"diabetes\", name, rmse])\n",
        "\n",
        "      X, y = fetch_california_housing(return_X_y=True)\n",
        "      X_train, X_test, y_train, y_test = train_test_split(X[:1000,:], y[:1000], test_size=0.2, random_state=42)\n",
        "      regressor = BoosterRegressor(obj=RegressorClass(), n_estimators=100, learning_rate=0.1,\n",
        "                                  n_hidden_features=10, verbose=verbose, seed=42)\n",
        "      start = time()\n",
        "      regressor.fit(X_train, y_train)\n",
        "      y_pred = regressor.predict(X_test)\n",
        "      print(f\"Elapsed: {time() - start} s\")\n",
        "      rmse = root_mean_squared_error(y_test, y_pred)\n",
        "      print(f\"RMSE for regression: {rmse:.4f}\")\n",
        "      results_regressors.append([\"housing\", name, rmse])\n",
        "\n",
        "      # Classification Example\n",
        "      X, y = load_iris(return_X_y=True)\n",
        "      X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "      classifier = BoosterClassifier(obj=RegressorClass(), n_estimators=100, learning_rate=0.1,\n",
        "                                    n_hidden_features=10, verbose=verbose, seed=42)\n",
        "      start = time()\n",
        "      try:\n",
        "          classifier.fit(X_train, y_train)\n",
        "      except Exception as e: # this is for Windows users\n",
        "          y_train = y_train.astype('int32')\n",
        "          classifier.fit(X_train, y_train)\n",
        "      y_pred = classifier.predict(X_test)\n",
        "      print(f\"Elapsed: {time() - start} s\")\n",
        "      accuracy = accuracy_score(y_test, y_pred)\n",
        "      print(f\"Accuracy for classification: {accuracy:.4f}\")\n",
        "      results_classifiers.append([\"iris\", name, accuracy])\n",
        "\n",
        "      X, y = load_wine(return_X_y=True)\n",
        "      X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "      classifier = BoosterClassifier(obj=RegressorClass(), n_estimators=100, learning_rate=0.1,\n",
        "                                    n_hidden_features=10, verbose=verbose, seed=42)\n",
        "      start = time()\n",
        "      try:\n",
        "          classifier.fit(X_train, y_train)\n",
        "      except Exception as e: # this is for Windows users\n",
        "          y_train = y_train.astype('int32')\n",
        "          classifier.fit(X_train, y_train)\n",
        "      y_pred = classifier.predict(X_test)\n",
        "      print(f\"Elapsed: {time() - start} s\")\n",
        "      accuracy = accuracy_score(y_test, y_pred)\n",
        "      print(f\"Accuracy for classification: {accuracy:.4f}\")\n",
        "      results_classifiers.append([\"wine\", name, accuracy])\n",
        "\n",
        "      X, y = load_breast_cancer(return_X_y=True)\n",
        "      X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "      classifier = BoosterClassifier(obj=RegressorClass(), n_estimators=100, learning_rate=0.1,\n",
        "                                    n_hidden_features=10, verbose=verbose, seed=42)\n",
        "      start = time()\n",
        "      try:\n",
        "          classifier.fit(X_train, y_train)\n",
        "      except Exception as e:\n",
        "          y_train = y_train.astype('int32')\n",
        "          classifier.fit(X_train, y_train)\n",
        "      y_pred = classifier.predict(X_test)\n",
        "      print(f\"Elapsed: {time() - start} s\")\n",
        "      accuracy = accuracy_score(y_test, y_pred)\n",
        "      print(f\"Accuracy for classification: {accuracy:.4f}\")\n",
        "      results_classifiers.append([\"breast_cancer\", name, accuracy])\n",
        "\n",
        "      X, y = load_digits(return_X_y=True)\n",
        "      X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "      classifier = BoosterClassifier(obj=RegressorClass(), n_estimators=100, learning_rate=0.1,\n",
        "                                    n_hidden_features=10, verbose=verbose, seed=42)\n",
        "      start = time()\n",
        "      try:\n",
        "          classifier.fit(X_train, y_train)\n",
        "      except Exception as e:\n",
        "          y_train = y_train.astype('int32')\n",
        "          classifier.fit(X_train, y_train)\n",
        "      y_pred = classifier.predict(X_test)\n",
        "      print(f\"Elapsed: {time() - start} s\")\n",
        "      accuracy = accuracy_score(y_test, y_pred)\n",
        "      print(f\"Accuracy for classification: {accuracy:.4f}\")\n",
        "      results_classifiers.append([\"digits\", name, accuracy])\n",
        "    except Exception as e:\n",
        "      continue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZYwRl7dNEUoT",
        "outputId": "d8b19f22-0e2d-4007-c010-a5b8a1d4a3d7"
      },
      "outputs": [],
      "source": [
        "df_results_regressors = pd.DataFrame(results_regressors, columns=['Dataset', 'Model', 'RMSE'])\n",
        "df_results_regressors.sort_values(by='RMSE', ascending=True, inplace=True)\n",
        "\n",
        "df_results_classifiers = pd.DataFrame(results_classifiers, columns=['Dataset', 'Model', 'Accuracy'])\n",
        "df_results_classifiers.sort_values(by='Accuracy', ascending=False, inplace=True)\n",
        "\n",
        "df_results_regressors_diabetes = df_results_regressors[df_results_regressors['Dataset'] == 'diabetes']\n",
        "df_results_regressors_housing = df_results_regressors[df_results_regressors['Dataset'] == 'housing']\n",
        "df_results_classifiers_iris = df_results_classifiers[df_results_classifiers['Dataset'] == 'iris']\n",
        "df_results_classifiers_wine = df_results_classifiers[df_results_classifiers['Dataset'] == 'wine']\n",
        "df_results_classifiers_breast_cancer = df_results_classifiers[df_results_classifiers['Dataset'] == 'breast_cancer']\n",
        "df_results_classifiers_digits = df_results_classifiers[df_results_classifiers['Dataset'] == 'digits']\n",
        "\n",
        "print(\"Best regressors:\")\n",
        "display(df_results_regressors_diabetes)\n",
        "display(df_results_regressors_housing)\n",
        "\n",
        "print(\"\\nBest classifiers:\")\n",
        "display(df_results_classifiers_iris)\n",
        "display(df_results_classifiers_wine)\n",
        "display(df_results_classifiers_breast_cancer)\n",
        "display(df_results_classifiers_digits)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MyyzhHtSXoRq"
      },
      "source": [
        "# 3 - Time series forecasting using `nnetsauce.MTS`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YiifSzvecdzu"
      },
      "outputs": [],
      "source": [
        "!pip install nnetsauce"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "VCqSzTKIcZZY",
        "outputId": "435e217a-121f-484c-9d6a-0daa22a32c56"
      },
      "outputs": [],
      "source": [
        "import nnetsauce as ns\n",
        "import pandas as pd\n",
        "from sklearn.utils import all_estimators\n",
        "from tqdm import tqdm\n",
        "from sklearn.utils.multiclass import type_of_target\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "\n",
        "\n",
        "# Get all scikit-learn regressors\n",
        "estimators = all_estimators(type_filter='regressor')\n",
        "\n",
        "results_regressors = []\n",
        "results_classifiers = []\n",
        "\n",
        "verbose = 0\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/Techtonique/\"\n",
        "url += \"datasets/main/time_series/multivariate/\"\n",
        "url += \"ice_cream_vs_heater.csv\"\n",
        "df_temp = pd.read_csv(url)\n",
        "df_temp.index = pd.DatetimeIndex(df_temp.date)\n",
        "# must have# first other difference\n",
        "df_icecream = df_temp.drop(columns=['date']).diff().dropna()\n",
        "\n",
        "for name, RegressorClass in tqdm(estimators):\n",
        "\n",
        "    if name in ['AdaBoostRegressor', 'MultiOutputRegressor', 'MultiOutputClassifier', 'StackingRegressor', 'StackingClassifier',\n",
        "                    'VotingRegressor', 'VotingClassifier', 'TransformedTargetRegressor', 'RegressorChain',\n",
        "                    'GradientBoostingRegressor', 'HistGradientBoostingRegressor', 'RandomForestRegressor',\n",
        "                    'ExtraTreesRegressor', 'MLPRegressor', 'TheilSenRegressor']:\n",
        "\n",
        "        continue\n",
        "\n",
        "    try:\n",
        "      print(f\"\\nRunning with {name}\")\n",
        "      # Regression Examples\n",
        "      mdl = BoosterRegressor(obj=RegressorClass(), n_estimators=100, learning_rate=0.1,\n",
        "                                  n_hidden_features=10, verbose=verbose, seed=42)\n",
        "      regr = ns.MTS(obj=mdl,\n",
        "                    type_pi=\"scp2-kde\",\n",
        "                    replications=250,\n",
        "                    lags=20,\n",
        "                    show_progress=False)\n",
        "      regr.fit(df_icecream)\n",
        "      regr.predict(h=30)\n",
        "      regr.plot(\"heater\", type_plot=\"pi\")\n",
        "    except Exception as e:\n",
        "      print(e)\n",
        "      continue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J4XM78dAdFZZ"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
